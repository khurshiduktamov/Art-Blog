{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6353627,"sourceType":"datasetVersion","datasetId":3659326}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/khurshiduktamov/portfolio-diabet-diagnosis-v1?scriptVersionId=157974249\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-07T00:35:50.596368Z","iopub.execute_input":"2024-01-07T00:35:50.596916Z","iopub.status.idle":"2024-01-07T00:35:50.607176Z","shell.execute_reply.started":"2024-01-07T00:35:50.596875Z","shell.execute_reply":"2024-01-07T00:35:50.60575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## CRSIP-DM Methodology\n<img src=\"https://cdn.sketchbubble.com/pub/media/catalog/product/optimized1/d/0/d063643deb841c9084106b83a7db3810cbe35aaa29adc1bbcd818b1d396e2f3f/crisp-dm-mc-slide1.png\" alt=\"CRISP-DM\" width=\"800\"/>","metadata":{}},{"cell_type":"markdown","source":"1. **Business Understanding:**\n   - Define the problem you are trying to solve from a business perspective.\n   - Determine the goals and objectives of the project.\n\n2. **Data Understanding:**\n   - Collect initial data and explore its characteristics.\n   - Identify data quality issues and gain insights into the structure and content of the data.\n\n3. **Data Preparation:**\n   - Cleanse and preprocess the data to address issues identified in the data understanding phase.\n   - Select relevant features and create new features if necessary.\n\n4. **Modeling:**\n   - Choose appropriate modeling techniques based on the nature of the problem and data.\n   - Build and train machine learning models on the prepared data.\n\n5. **Evaluation:**\n   - Evaluate the performance of the models against business objectives.\n   - Fine-tune models and iterate on the process if needed.\n\n6. **Deployment:**\n   - Deploy the chosen model into a production environment.\n   - Implement monitoring and maintenance procedures.\n","metadata":{}},{"cell_type":"markdown","source":"# Business Understanding\nThe business goal for this task is to develop a predictive model that can accurately predict whether a patient has diabetes based on diagnostic measurements. The model aims to assist healthcare professionals in the early identification of individuals at risk of diabetes, allowing for timely intervention, monitoring, and treatment. The ultimate objective is to improve the health outcomes of patients by providing an effective tool for diabetes risk assessment.\n\nKey components of the business goal include:\n\n1. **Early Detection:** The model should be able to identify individuals at risk of diabetes at an early stage, enabling proactive healthcare interventions.\n\n2. **Risk Assessment:** Provide a quantitative measure of the likelihood of diabetes based on diagnostic measurements, supporting healthcare professionals in making informed decisions.\n\nIn summary, the business goal is centered around leveraging predictive modeling to enhance diabetes risk assessment and management, contributing to better patient care and public health outcomes.","metadata":{}},{"cell_type":"markdown","source":"**Goals:**\n\n1. **Develop Predictive Model:**\n   - *Objective:* Create a machine learning model for diabetes prediction. We use Classification algorithms as we have to classify as Yes/No.\n\n2. **Enhance Early Detection:**\n   - *Objective:* Improve early identification of diabetes risk. To determine if the model enables early detection, we can analyze the confusion matrix, specifically focusing on the False Negatives (FN) and True Positives (TP). In the context of diabetes prediction:\n\n    False Negatives (FN): These are cases where the actual outcome is positive (indicating diabetes), but the model predicts negative. In the context of early detection, these are individuals who have diabetes but were not identified by the model.\n\n    True Positives (TP): These are cases where the actual outcome is positive, and the model correctly predicts positive. In the context of early detection, these are individuals who have diabetes and were correctly identified by the model. \n    For early detection, we want to minimize False Negatives and maximize True Positives. If our model has a low number of False Negatives and a high number of True Positives, it suggests that the model is effective in identifying individuals at risk of diabetes, contributing to early detection.\n\n**Objectives:**\n\n1. **Data Preparation:**\n   - *Objective:* Gather and preprocess relevant dataset.\n\n2. **EDA and Feature Selection:**\n   - *Objective:* Gain insights, select features, and potentially engineer new ones.\n\n3. **Model Development and Evaluation:**\n   - *Objective:* Implement, train, and evaluate machine learning models.\n\n4. **Hyperparameter Tuning:**\n   - *Objective:* Fine-tune model hyperparameters for optimal performance.\n\n5. **Interpretability and Deployment:**\n   - *Objective:* Ensure model interpretability and deploy for accessibility.\n\n6. **Documentation and Reporting:**\n   - *Objective:* Document the project and generate a comprehensive report.\n\n7. **Continuous Monitoring and Improvement:**\n   - *Objective:* Monitor real-world performance and consider updates as needed.\n\nThese concise goals and objectives aim to develop a practical and impactful predictive model for diabetes, supporting early detection and informed healthcare decisions.","metadata":{}},{"cell_type":"markdown","source":"# **Data understanding**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/healthcare-diabetes/Healthcare-Diabetes.csv\")\ndf","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:50.610384Z","iopub.execute_input":"2024-01-07T00:35:50.611379Z","iopub.status.idle":"2024-01-07T00:35:50.64925Z","shell.execute_reply.started":"2024-01-07T00:35:50.611329Z","shell.execute_reply":"2024-01-07T00:35:50.647733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Uzbek**: Yuqoridagi ma'lumotlar to'plami Hindistonning Qandli diabet va buyrak kasalliklari milliy institutidan olingan. Maqsad diagnostik o'lchovlar asosida bemorda diabet bor-yo'qligini taxmin qilishdir.\nTarkib\n\nDataset ichida barcha bemorlar kamida 21 yoshli ayollari.\nUstunlar\n\n    Pregnancies: homilador bo'lish soni\n    Glucose: glyukozaga test natijasi\n    BloodPressure: diastolik qon bosimi (mm Hg)\n    SkinThickness: Triceps teri burmasining qalinligi (mm)\n    Insulin: 2 soatlik sarum insulini (mu U/ml)\n    BMI: Tana massasi indeksi (vazn kg / (m bo'yi) ^ 2)\n    DiabetesPedigreeFunction: diabetning naslchilik funktsiyasi\n    Age: Yosh (yil)\n    Outcome: Class (0 - diabet yo'q, 1 - diabet)","metadata":{}},{"cell_type":"markdown","source":"**English**: The medical dataset was obtained from the National Institute of Diabetes and Cancer, India. The goal is to predict whether a patient has diabetes based on diagnostic measurements.\nContent\n\nAll patients in the dataset are women at least 21 years old.\nColumns\n\n      Pregnant women: number of pregnancies\n      Glucose: Glucose test result\n      Blood pressure: diastolic blood level (mm Hg)\n      SkinThickness: Triceps Skinfold Surface (mm)\n      Insulin: 2-hour serum insulin (mu U/ml)\n      BMI: Body Mass Index (weight in kg / (height in m) ^ 2)\n      DiabetesPedigreeFunction: Diabetes Pedigree Support\n      Age: Age (years)\n      Result: Class (0 - no diabetes, 1 - diabetes)","metadata":{}},{"cell_type":"markdown","source":"**Exploratory Data Analysis and Features selection**","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:50.650988Z","iopub.execute_input":"2024-01-07T00:35:50.652142Z","iopub.status.idle":"2024-01-07T00:35:50.668608Z","shell.execute_reply.started":"2024-01-07T00:35:50.652084Z","shell.execute_reply":"2024-01-07T00:35:50.667324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:50.669998Z","iopub.execute_input":"2024-01-07T00:35:50.670364Z","iopub.status.idle":"2024-01-07T00:35:50.683374Z","shell.execute_reply.started":"2024-01-07T00:35:50.670333Z","shell.execute_reply":"2024-01-07T00:35:50.681972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* df is pretty good without any object columns nor NaN values","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:50.686961Z","iopub.execute_input":"2024-01-07T00:35:50.687368Z","iopub.status.idle":"2024-01-07T00:35:50.7351Z","shell.execute_reply.started":"2024-01-07T00:35:50.687334Z","shell.execute_reply":"2024-01-07T00:35:50.733966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*   We need to standartize the inputs for models\n\n**Zero values**\n*   Glucose: [You may feel very confused, pass out, or have a seizure. Without prompt treatment, severe hypoglycemia may lead to a coma or even death. ](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwi40_fgmceDAxUlQfEDHVDGDQsQFnoECBAQAw&url=https%3A%2F%2Fwww.endocrine.org%2Fpatient-engagement%2Fendocrine-library%2Fsevere-hypoglycemia&usg=AOvVaw2nfoi5YZpLztMF0aqtwqrn&opi=89978449) - ***so we need to remove rows with 0 values in Glucose column if we have to use this column as a feature***\n*   Diastolic Blood Pressure: [Extremely low or zero DBP is a possibility in cases of severe hypotension, stiff arteries in elderly, diabetes, arteriovenous malformation, and aortic dissection.](https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwj8xZXJnceDAxUHExAIHbhWDBEQFnoECBEQAw&url=https%3A%2F%2Fjournals.lww.com%2Fiaaf%2Ffulltext%2F2016%2F17010%2F_zero__diastolic_blood_pressure.10.aspx&usg=AOvVaw1gs73dVbaDHf83zN0GXBpR&opi=89978449) - ***No action required***\n*   SkinThickness: It's possible for skin thickness measurements, such as \"Triceps Skinfold Surface (mm),\" to have a value of 0 in certain circumstances. However, a measurement of 0 may not be physiologically meaningful in many cases, and it could indicate missing or incorrect data rather than a valid measurement. - ChatGPT3.5 ***No action required - we can use BMI instead(Depending on correlation of course) or delete 0 values***\n*   Insulin: In a physiological context, it's less likely for the insulin concentration in a 2-hour serum sample to be exactly 0. However, in a dataset, a recorded value of 0 might have several interpretations:     \n    1. Missing Data or Measurement Limitation: A 0 value might indicate missing data or that the measurement fell below the detection limit of the assay used to measure insulin. Some laboratory assays may not accurately measure very low concentrations.\n\n    2. Data Entry Error: It could also be a data entry error or an encoding convention for missing or undetectable values. - ChatGPT3.5\n    ***No action required. Decide before using this column as a feature***\n\n* BMI: In the context of Body Mass Index (BMI), a value of 0 is not physiologically meaningful and is likely indicative of missing or incorrect data rather than a valid measurement. - ChatGPT3.5 ***We have to remove rows with 0 value if we are using this column as a feature***\n\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# Assuming 'df' is your DataFrame\nsns.set(style=\"darkgrid\")\n\n# Create a countplot for the 'Outcome' variable\nplt.figure(figsize=(7, 5))\nsns.countplot(x='Outcome', data=df)\n\n# Add labels and title\nplt.xlabel('Outcome (Diabetes: No/Yes)')\nplt.ylabel('Count')\nplt.title('Distribution of Diabetes Outcome')\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:50.736395Z","iopub.execute_input":"2024-01-07T00:35:50.736831Z","iopub.status.idle":"2024-01-07T00:35:51.041079Z","shell.execute_reply.started":"2024-01-07T00:35:50.736784Z","shell.execute_reply":"2024-01-07T00:35:51.039834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.Outcome.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:51.042889Z","iopub.execute_input":"2024-01-07T00:35:51.04371Z","iopub.status.idle":"2024-01-07T00:35:51.053366Z","shell.execute_reply.started":"2024-01-07T00:35:51.043672Z","shell.execute_reply":"2024-01-07T00:35:51.052164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* We will try without equalizing values first. Otherwise we need to equalize the results so that the model is not skewed to one side.","metadata":{}},{"cell_type":"code","source":"df.corr()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:51.055309Z","iopub.execute_input":"2024-01-07T00:35:51.055659Z","iopub.status.idle":"2024-01-07T00:35:51.084257Z","shell.execute_reply.started":"2024-01-07T00:35:51.055627Z","shell.execute_reply":"2024-01-07T00:35:51.082919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Easier with visualisation. Let's use HEATMAP**","metadata":{}},{"cell_type":"code","source":"# Calculate the correlation matrix\ncorrelation_matrix = df.corr()\n\n# Create a heatmap using seaborn\nplt.figure(figsize=(12, 6))\nsns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".4f\", linewidths=.5)\n\n# Show the plot\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:51.085599Z","iopub.execute_input":"2024-01-07T00:35:51.086168Z","iopub.status.idle":"2024-01-07T00:35:51.925533Z","shell.execute_reply.started":"2024-01-07T00:35:51.086129Z","shell.execute_reply":"2024-01-07T00:35:51.924209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the correlation with 'Outcome'\ncorrelation_with_outcome = df.corrwith(df['Outcome']).sort_values(ascending=False)\n\n# Create a heatmap using seaborn for correlation with 'Outcome'\nplt.figure(figsize=(8, 6))\nsns.heatmap(pd.DataFrame(correlation_with_outcome, columns=['correlation']), annot=True, cmap='coolwarm', fmt=\".4f\", linewidths=.5)\n\n# Show the plot\nplt.title('Correlation with Outcome')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:51.927211Z","iopub.execute_input":"2024-01-07T00:35:51.927624Z","iopub.status.idle":"2024-01-07T00:35:53.029105Z","shell.execute_reply.started":"2024-01-07T00:35:51.927587Z","shell.execute_reply":"2024-01-07T00:35:53.027898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Data preparation**","metadata":{}},{"cell_type":"code","source":"# saving the features to another df_model\ndf_model = df[['Pregnancies', 'Age', 'BMI', 'Glucose', 'Outcome', 'DiabetesPedigreeFunction', 'Insulin', 'SkinThickness', 'BloodPressure']].copy()\nprint(df_model.shape)\n\n# Deleting 0 values from BMI and Glucose\ndf_model = df_model[df_model['Glucose'] !=0 ]\ndf_model = df_model[df_model['BMI'] !=0 ]\ndf_model = df_model[df_model['Insulin'] !=0 ]\ndf_model = df_model[df_model['BloodPressure'] !=0 ]\ndf_model = df_model[df_model['SkinThickness'] !=0 ]\nprint(df_model.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.03054Z","iopub.execute_input":"2024-01-07T00:35:53.030941Z","iopub.status.idle":"2024-01-07T00:35:53.048335Z","shell.execute_reply.started":"2024-01-07T00:35:53.030905Z","shell.execute_reply":"2024-01-07T00:35:53.046891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_model.Outcome.value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.049985Z","iopub.execute_input":"2024-01-07T00:35:53.050366Z","iopub.status.idle":"2024-01-07T00:35:53.068249Z","shell.execute_reply.started":"2024-01-07T00:35:53.050336Z","shell.execute_reply":"2024-01-07T00:35:53.066892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"960-467","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.069755Z","iopub.execute_input":"2024-01-07T00:35:53.070279Z","iopub.status.idle":"2024-01-07T00:35:53.083117Z","shell.execute_reply.started":"2024-01-07T00:35:53.070245Z","shell.execute_reply":"2024-01-07T00:35:53.081733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Let's try without equalizing Outcome values first","metadata":{}},{"cell_type":"code","source":"# # Equalizing Outcome column so model didn't skew to one side.\n\n# # Assuming 'Outcome' is the column representing diabetes status\n# # Replace 'df' with your actual DataFrame name\n# df0 = df_model[df_model['Outcome'] == 0]\n\n# # Number of rows to drop randomly\n# rows_to_drop = 493\n\n# # Randomly drop rows\n# random_rows = df0.sample(n=rows_to_drop, random_state=42)  # You can change the random_state for reproducibility\n# df_dropped = df0.drop(random_rows.index)\n\n# # Remaining rows in the DataFrame (Outcome 1)\n# df_remaining = df_model[df_model['Outcome'] == 1]\n\n# # Concatenate the randomly dropped rows and the remaining rows\n# df_merged = pd.concat([df_dropped, df_remaining], ignore_index=True)\n\n# # Replace 'df_merged' with your actual merged DataFrame name\n# df_merged = df_merged.sample(frac=1.0, random_state=42)  # You can change the random_state for reproducibility\n\n# print(df_merged.shape)\n# print(df_merged.Outcome.value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.088417Z","iopub.execute_input":"2024-01-07T00:35:53.08925Z","iopub.status.idle":"2024-01-07T00:35:53.099148Z","shell.execute_reply.started":"2024-01-07T00:35:53.089206Z","shell.execute_reply":"2024-01-07T00:35:53.09751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# # Split data into features and target\n# x = df_merged.drop('Outcome', axis=1)\n# y = df_merged['Outcome']\n\n\n# Split data into features and target\nx = df_model.drop('Outcome', axis=1)\ny = df_model['Outcome']\n\n# Split data into training and testing sets\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.100474Z","iopub.execute_input":"2024-01-07T00:35:53.1009Z","iopub.status.idle":"2024-01-07T00:35:53.119471Z","shell.execute_reply.started":"2024-01-07T00:35:53.100866Z","shell.execute_reply":"2024-01-07T00:35:53.117704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.121273Z","iopub.execute_input":"2024-01-07T00:35:53.121839Z","iopub.status.idle":"2024-01-07T00:35:53.135573Z","shell.execute_reply.started":"2024-01-07T00:35:53.121769Z","shell.execute_reply":"2024-01-07T00:35:53.134575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Standardization**","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nmin_mix_scaler = MinMaxScaler()\n\nx_train_scaled = min_mix_scaler.fit_transform(x_train)\nx_test_scaled = min_mix_scaler.fit_transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.137088Z","iopub.execute_input":"2024-01-07T00:35:53.137438Z","iopub.status.idle":"2024-01-07T00:35:53.157523Z","shell.execute_reply.started":"2024-01-07T00:35:53.137408Z","shell.execute_reply":"2024-01-07T00:35:53.15649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Modeling & Evaluation**","metadata":{}},{"cell_type":"markdown","source":"# Logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Step 2: Model Training\n# Create a Logistic Regression model\nlogreg_model = LogisticRegression(random_state=42)\n\n# Train the model on the scaled training data\nlogreg_model.fit(x_train_scaled, y_train)\n\n# Step 3: Model Evaluation\n# Make predictions on the testing set\ny_pred = logreg_model.predict(x_test_scaled)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclassification_rep = classification_report(y_test, y_pred)\n\n# Display results\nprint(f'Accuracy: {accuracy:.2f}')\nprint('\\nConfusion Matrix:')\nprint(conf_matrix)\nprint('\\nClassification Report:')\nprint(classification_rep)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.159224Z","iopub.execute_input":"2024-01-07T00:35:53.159933Z","iopub.status.idle":"2024-01-07T00:35:53.190124Z","shell.execute_reply.started":"2024-01-07T00:35:53.159896Z","shell.execute_reply":"2024-01-07T00:35:53.188881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check if model is not skewed to one side**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, precision_recall_curve, auc\n\n# Calculate ROC curve\nfpr, tpr, _ = roc_curve(y_test, y_pred_prob)\nroc_auc = auc(fpr, tpr)\n\n# Calculate Precision-Recall curve\nprecision, recall, _ = precision_recall_curve(y_test, y_pred_prob)\n\n# Plot ROC curve and Precision-Recall curve\nplt.figure(figsize=(12, 6))\n\n# ROC curve\nplt.subplot(1, 2, 1)\nplt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve')\nplt.legend(loc='lower right')\n\n# Precision-Recall curve\nplt.subplot(1, 2, 2)\nplt.plot(recall, precision, color='green', lw=2, label='Precision-Recall curve')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.title('Precision-Recall Curve')\nplt.legend(loc='upper right')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:53.191678Z","iopub.execute_input":"2024-01-07T00:35:53.192086Z","iopub.status.idle":"2024-01-07T00:35:54.142874Z","shell.execute_reply.started":"2024-01-07T00:35:53.192052Z","shell.execute_reply":"2024-01-07T00:35:54.141439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Decision Tree","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Step 1: Model Training\n# Create a Decision Tree model\ndecision_tree_model = DecisionTreeClassifier(random_state=42)\n\n# Train the model on the scaled training data\ndecision_tree_model.fit(x_train_scaled, y_train)\n\n# Step 2: Model Evaluation\n# Make predictions on the testing set\ny_pred_tree = decision_tree_model.predict(x_test_scaled)\n\n# Evaluate the Decision Tree model\naccuracy_tree = accuracy_score(y_test, y_pred_tree)\nconf_matrix_tree = confusion_matrix(y_test, y_pred_tree)\nclassification_rep_tree = classification_report(y_test, y_pred_tree)\n\n# Display results for Decision Tree\nprint(f'Decision Tree Accuracy: {accuracy_tree:.2f}')\nprint('\\nDecision Tree Confusion Matrix:')\nprint(conf_matrix_tree)\nprint('\\nDecision Tree Classification Report:')\nprint(classification_rep_tree)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:54.144593Z","iopub.execute_input":"2024-01-07T00:35:54.145074Z","iopub.status.idle":"2024-01-07T00:35:54.17746Z","shell.execute_reply.started":"2024-01-07T00:35:54.145031Z","shell.execute_reply":"2024-01-07T00:35:54.176055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Check if model is not skewed to one side**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\n\n# Get predicted probabilities for class 1\ny_probs_tree = decision_tree_model.predict_proba(x_test_scaled)[:, 1]\n\n# Compute ROC curve and AUC\nfpr_tree, tpr_tree, _ = roc_curve(y_test, y_probs_tree)\nroc_auc_tree = auc(fpr_tree, tpr_tree)\n\n# Plot ROC curve for Decision Tree\nplt.figure(figsize=(8, 6))\nplt.plot(fpr_tree, tpr_tree, color='darkgreen', lw=2, label=f'Decision Tree ROC curve (AUC = {roc_auc_tree:.2f})')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Decision Tree ROC Curve')\nplt.legend(loc='lower right')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:54.179287Z","iopub.execute_input":"2024-01-07T00:35:54.179682Z","iopub.status.idle":"2024-01-07T00:35:54.629006Z","shell.execute_reply.started":"2024-01-07T00:35:54.179647Z","shell.execute_reply":"2024-01-07T00:35:54.627784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest (Highest accuracy)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Create a Random Forest model\nrandom_forest_model = RandomForestClassifier(random_state=42)\n\n# Train the model on the scaled training data\nrandom_forest_model.fit(x_train_scaled, y_train)\n\n# Make predictions on the testing set\ny_pred_rf = random_forest_model.predict(x_test_scaled)\n\n# Evaluate the Random Forest model\naccuracy_rf = accuracy_score(y_test, y_pred_rf)\nconf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\nclassification_rep_rf = classification_report(y_test, y_pred_rf)\n\n# Display results for Random Forest\nprint(f'Random Forest Accuracy: {accuracy_rf:.2f}')\nprint('\\nRandom Forest Confusion Matrix:')\nprint(conf_matrix_rf)\nprint('\\nRandom Forest Classification Report:')\nprint(classification_rep_rf)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:54.631237Z","iopub.execute_input":"2024-01-07T00:35:54.631643Z","iopub.status.idle":"2024-01-07T00:35:54.996285Z","shell.execute_reply.started":"2024-01-07T00:35:54.631607Z","shell.execute_reply":"2024-01-07T00:35:54.99489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\n# Plot the confusion matrix using a heatmap\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['No Diabetes', 'Diabetes'], yticklabels=['No Diabetes', 'Diabetes'])\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:54.998375Z","iopub.execute_input":"2024-01-07T00:35:54.998822Z","iopub.status.idle":"2024-01-07T00:35:55.407033Z","shell.execute_reply.started":"2024-01-07T00:35:54.998771Z","shell.execute_reply":"2024-01-07T00:35:55.405488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(pd.Series(y_pred_rf).value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:55.40878Z","iopub.execute_input":"2024-01-07T00:35:55.409309Z","iopub.status.idle":"2024-01-07T00:35:55.418491Z","shell.execute_reply.started":"2024-01-07T00:35:55.40926Z","shell.execute_reply":"2024-01-07T00:35:55.416884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking if model is not skewed to one side. ROC and Precision-Recall Curve**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_curve\n\n# Compute Precision-Recall curve\nprecision_rf, recall_rf, _ = precision_recall_curve(y_test, y_probs_rf)\n\n# Plot ROC curve and Precision-Recall curve side by side\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n\n# Plot ROC curve for Random Forest\naxes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'Random Forest ROC curve (AUC = {roc_auc:.2f})')\naxes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\naxes[0].set_xlabel('False Positive Rate')\naxes[0].set_ylabel('True Positive Rate')\naxes[0].set_title('Random Forest ROC Curve')\naxes[0].legend(loc='lower right')\n\n# Plot Precision-Recall curve for Random Forest\naxes[1].plot(recall_rf, precision_rf, color='darkorange', lw=2, label='Random Forest')\naxes[1].set_xlabel('Recall')\naxes[1].set_ylabel('Precision')\naxes[1].set_title('Random Forest Precision-Recall Curve')\naxes[1].legend(loc='upper right')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:55.41998Z","iopub.execute_input":"2024-01-07T00:35:55.420358Z","iopub.status.idle":"2024-01-07T00:35:56.180122Z","shell.execute_reply.started":"2024-01-07T00:35:55.420322Z","shell.execute_reply":"2024-01-07T00:35:56.178562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* In an ideal scenario, the ROC curve should hug the top-left corner, and the AUC (Area Under the Curve) value should be close to 1. This indicates a good balance between true positive rate and false positive rate. So, the model is well balanced.\n* For a balanced model, the Precision-Recall curve should show high precision and recall across different thresholds. If the curves look good, it provides further evidence that our model is not skewed.","metadata":{}},{"cell_type":"markdown","source":"# Support Vector Machine SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n\n# Create an SVM model\nsvm_model = SVC(random_state=42)\n\n# Train the model on the scaled training data\nsvm_model.fit(x_train_scaled, y_train)\n\n# Make predictions on the testing set\ny_pred_svm = svm_model.predict(x_test_scaled)\n\n# Evaluate the SVM model\naccuracy_svm = accuracy_score(y_test, y_pred_svm)\nconf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\nclassification_rep_svm = classification_report(y_test, y_pred_svm)\n\n# Display results for SVM\nprint(f'SVM Accuracy: {accuracy_svm:.2f}')\nprint('\\nSVM Confusion Matrix:')\nprint(conf_matrix_svm)\nprint('\\nSVM Classification Report:')\nprint(classification_rep_svm)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:56.18205Z","iopub.execute_input":"2024-01-07T00:35:56.183489Z","iopub.status.idle":"2024-01-07T00:35:56.247064Z","shell.execute_reply.started":"2024-01-07T00:35:56.183448Z","shell.execute_reply":"2024-01-07T00:35:56.245425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross Validation with Gradient Boost","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import GradientBoostingClassifier\n\n# Create a Gradient Boosting model\ngbm_model = GradientBoostingClassifier(random_state=42)\n\n# Perform cross-validation\ncv_scores_gbm = cross_val_score(gbm_model, x_train_scaled, y_train, cv=5, scoring='accuracy')\n\n# Display cross-validation results for Gradient Boosting\nprint(f'Cross-Validation Scores for Gradient Boosting: {cv_scores_gbm}')\nprint(f'Mean Accuracy: {cv_scores_gbm.mean():.2f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:56.24854Z","iopub.execute_input":"2024-01-07T00:35:56.248925Z","iopub.status.idle":"2024-01-07T00:35:57.467642Z","shell.execute_reply.started":"2024-01-07T00:35:56.248891Z","shell.execute_reply":"2024-01-07T00:35:57.466402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# XGB (Second highest accuracy)","metadata":{}},{"cell_type":"code","source":"from xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Create an XGBoost model\nxgb_model = XGBClassifier(random_state=42)\n\n# Train the model on the scaled training data\nxgb_model.fit(x_train_scaled, y_train)\n\n# Make predictions on the testing set\ny_pred_xgb = xgb_model.predict(x_test_scaled)\n\n# Evaluate the XGBoost model\naccuracy_xgb = accuracy_score(y_test, y_pred_xgb)\nconf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\nclassification_rep_xgb = classification_report(y_test, y_pred_xgb)\n\n# Display results for XGBoost\nprint(f'XGBoost Accuracy: {accuracy_xgb:.2f}')\nprint('\\nXGBoost Confusion Matrix:')\nprint(conf_matrix_xgb)\nprint('\\nXGBoost Classification Report:')\nprint(classification_rep_xgb)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:57.469085Z","iopub.execute_input":"2024-01-07T00:35:57.469439Z","iopub.status.idle":"2024-01-07T00:35:57.578471Z","shell.execute_reply.started":"2024-01-07T00:35:57.469408Z","shell.execute_reply":"2024-01-07T00:35:57.577534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Checking if model is not skewed to one side**","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc, precision_recall_curve\n\n# Get predicted probabilities for class 1\ny_probs_xgb = xgb_model.predict_proba(x_test_scaled)[:, 1]\n\n# Compute ROC curve and AUC for XGBoost\nfpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_probs_xgb)\nroc_auc_xgb = auc(fpr_xgb, tpr_xgb)\n\n# Compute Precision-Recall curve\nprecision_xgb, recall_xgb, _ = precision_recall_curve(y_test, y_probs_xgb)\n\n# Plot ROC curve and Precision-Recall curve side by side\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n\n# Plot ROC curve for XGBoost\naxes[0].plot(fpr_xgb, tpr_xgb, color='darkorange', lw=2, label=f'XGBoost ROC curve (AUC = {roc_auc_xgb:.2f})')\naxes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\naxes[0].set_xlabel('False Positive Rate')\naxes[0].set_ylabel('True Positive Rate')\naxes[0].set_title('XGBoost ROC Curve')\naxes[0].legend(loc='lower right')\n\n# Plot Precision-Recall curve for XGBoost\naxes[1].plot(recall_xgb, precision_xgb, color='darkorange', lw=2, label='XGBoost')\naxes[1].set_xlabel('Recall')\naxes[1].set_ylabel('Precision')\naxes[1].set_title('XGBoost Precision-Recall Curve')\naxes[1].legend(loc='upper right')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:57.580234Z","iopub.execute_input":"2024-01-07T00:35:57.580922Z","iopub.status.idle":"2024-01-07T00:35:58.31529Z","shell.execute_reply.started":"2024-01-07T00:35:57.580889Z","shell.execute_reply":"2024-01-07T00:35:58.31427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Keras","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\n# Create a Sequential model\nmodel = Sequential()\n\n# Add layers to the model\nmodel.add(Dense(64, input_dim=x_train_scaled.shape[1], activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Display the model summary\nmodel.summary()\n\n# Train the model\nhistory = model.fit(x_train_scaled, y_train, epochs=20, batch_size=32, validation_split=0.2)\n\n# Evaluate the model on the test set\ntest_loss, test_acc = model.evaluate(x_test_scaled, y_test)\nprint(f'Test Accuracy: {test_acc:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-01-07T00:35:58.3171Z","iopub.execute_input":"2024-01-07T00:35:58.317832Z","iopub.status.idle":"2024-01-07T00:36:04.573829Z","shell.execute_reply.started":"2024-01-07T00:35:58.317767Z","shell.execute_reply":"2024-01-07T00:36:04.57285Z"},"trusted":true},"execution_count":null,"outputs":[]}]}